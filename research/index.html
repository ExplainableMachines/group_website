<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  


























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Research | Explainable Machine Learning Group</title>

<link rel="icon" href="/group_website/images/icon.png">

<meta name="title" content="Research">
<meta name="description" content="EML. This is the home of the Explainable Machine Learning research group of the Department for Computer Vision and Machine Learning of the Max Planck Institute for Informatics. Here, we provide an overview as well as all the details on our ongoing and past work around Explainability in Machine Learning, including generation of explanations for black box models, inherently interpretable neural network approaches, and their applications.">

<meta property="og:title" content="Research">
<meta property="og:site_title" content="Explainable Machine Learning Group">
<meta property="og:description" content="EML. This is the home of the Explainable Machine Learning research group of the Department for Computer Vision and Machine Learning of the Max Planck Institute for Informatics. Here, we provide an overview as well as all the details on our ongoing and past work around Explainability in Machine Learning, including generation of explanations for black box models, inherently interpretable neural network approaches, and their applications.">
<meta property="og:url" content="">
<meta property="og:image" content="">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Research">
<meta property="twitter:description" content="EML. This is the home of the Explainable Machine Learning research group of the Department for Computer Vision and Machine Learning of the Max Planck Institute for Informatics. Here, we provide an overview as well as all the details on our ongoing and past work around Explainability in Machine Learning, including generation of explanations for black box models, inherently interpretable neural network approaches, and their applications.">
<meta property="twitter:url" content="">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "Research",
    "description": "EML. This is the home of the Explainable Machine Learning research group of the Department for Computer Vision and Machine Learning of the Max Planck Institute for Informatics. Here, we provide an overview as well as all the details on our ongoing and past work around Explainability in Machine Learning, including generation of explanations for black box models, inherently interpretable neural network approaches, and their applications.",
    "headline": "Research",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/group_website/images/icon.png" }
    },
    "url": ""
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/group_website/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="preload" as="style" onload="this.onload = null; this.rel = 'stylesheet';">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/group_website/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/all.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/background.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/body.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/button.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/card.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/code.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/float.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/font.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/form.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/header.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/image.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/link.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/list.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/main.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/section.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/table.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/group_website/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/group_website/_scripts/anchors.js"></script>

  <script src="/group_website/_scripts/brain_logo.js"></script>

  <script src="/group_website/_scripts/dark-mode.js"></script>

  <script src="/group_website/_scripts/fetch-tags.js"></script>

  <script src="/group_website/_scripts/search.js"></script>

  <script src="/group_website/_scripts/site-search.js"></script>

  <script src="/group_website/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/group_website/images/background.jpg')" data-dark="true">
  <a href="/group_website/" class="home">
    <span class="brainContainer"></span>
    
      <span class="title" data-tooltip="Home">
        
          <span>Explainable Machine Learning Group</span>
        
        
          <span>EML</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/group_website/research/" data-tooltip="Published works">
          Research
        </a>
      
    
      
        <a href="/group_website/projects/" data-tooltip="Software, datasets, and more">
          Projects
        </a>
      
    
      
        <a href="/group_website/team/" data-tooltip="About our team">
          Team
        </a>
      
    
      
        <a href="/group_website/contact/" data-tooltip="Email, address, and location">
          Contact
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - wrap each table in div to allow for scrolling
  - filter out blank sections
-->








  
  
  

  <section class="background" data-size="page">
    <h1 id="research">
<i class="icon fa-solid fa-microscope"></i>Research</h1>

<p>Research is most fruitful (and most fun) at the intersection of different fields of research. At the core of our research is the development of methods that
give <em>global, human-interpretable explanations</em> for complex machine learning models, as well as the development of <em>inherently interpretable</em> machine learning models.
We study these topics touching the fields of <em>classical XAI, Data Mining, Neural Network Pruning, and Low-dimensional Embeddings</em>,
merging ideas to for example obtain a better understanding of which information is encoded in a neural network and how information flows between layers, or to inform neuro-symbolic
architecture designs for relevant problems in biology.</p>

<p>Putting our ideas into practice, we study Explainability of models in challenging biomedical tasks around <em>cancer</em>, where an understanding of the decision-making process of a model is essential
for a model to be deployed in practice. We further consider Explanability of <em>foundation models</em>, which is key to understand their success, but also to understand whether they align with human reasoning and do
not reflect harmful biases. Such an understanding is not only interesting, but soon required by law under the <em>EU AI act</em>.</p>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<div class="feature">
  <a class="feature-image" aria-label="Global Explanations">
    <img src="/group_website/images/explainn.png" loading="lazy" alt="Global Explanations" onerror="this.src = '/group_website/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Global Explanations</p>
    
    
<p><em>Post-hoc</em> explainability methods aim to provide explanations of what an already trained model, usually a neural network, learned and how it uses this information to arrive at a prediction.
While not making the network fully transparent, by providing a glimpse into the black box models these methods have the great advantage that they do not compromise performance, which is a desiderata for a neural network. 
The majority of post-hoc explanation approaches, however, focus on <em>instance-specific explanations</em>, giving insights into why a decision was made for a particular instance (e.g., saliency maps, GradCam, Integrated Gradients,
LIME, …).
We are interested in <em>global explanations</em> that describe the general information encoded for example by a group of neurons and discovering such feature-encoding neuron groups in the first place.</p>


  </div>
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<div class="feature">
  <a class="feature-image" aria-label="Neuro-symbolic architectures">
    <img src="/group_website/images/binaps.png" loading="lazy" alt="Neuro-symbolic architectures" onerror="this.src = '/group_website/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Neuro-symbolic architectures</p>
    
    
<p><em>Neuro-symbolic approaches</em> to machine learning promise full interpretability through <em>symbolic encodings</em> in a neural network that can be parsed and understood by a human domain expert. While highly interesting, these approaches remain largely theoretical, as such architectures are hard to define and even harder to optimize. We focus on recent advances for <em>binarized and ternarized neural network architectures</em> from different fields, such as ML for embedded devices, and how we can transfer these to neuro-symbolic learning. In several biological applications as well as settings with transactional data, such architectures already provide a fully interpretable approach that allows to derive new insights directly from the network.</p>


  </div>
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<div class="feature">
  <a class="feature-image" aria-label="Sparse Neural Networks">
    <img src="/group_website/images/pruning.png" loading="lazy" alt="Sparse Neural Networks" onerror="this.src = '/group_website/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Sparse Neural Networks</p>
    
    
<p><em>Sparse neural networks</em> not only provide more resource-efficient alternatives to their dense counterparts at same performance, captured by the <em>Lottery Ticket Hypothesis</em>, but also represent useful information in their network topology compared to the standard fully connected layers in dense networks.
We focus on the question of how we can prune networks to <em>extreme sparsity</em>, and how such sparse neural networks can then yield more explainable decision-making.</p>


  </div>
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<div class="feature">
  <a class="feature-image" aria-label="Low-dimensional Embeddings">
    <img src="/group_website/images/mnist_dtsne.png" loading="lazy" alt="Low-dimensional Embeddings" onerror="this.src = '/group_website/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Low-dimensional Embeddings</p>
    
    
<p>To discover and present <em>regularities and dependencies in complex, high-dimensional data</em>, human experts often resort to a visual exploration.
As a visual inspection or presentation is bound to two or three-dimensional spaces, the field of <em>low-dimensional embeddings</em> focuses on developing methods
to map high-dimensional data to such low-dimensional, visualizable spaces while <em>keeping the main structure of the data intact</em>.
While these approaches enjoy tremendous interest in the sciences, such as biology, the limitations on what structures they preserves and which ones are lost, or which biases are introduced are under constant debate.
We are interested in <em>studying these limitations</em> both empirically and theoretically, <em>develop novel approaches</em> to this problem, and use those to visually <em>explore the neural activation landscapes</em> of neural networks</p>


  </div>
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<h2 id="list-of-publications">List of Publications</h2>

<h3 id="2024">2024</h3>

<p>Walter, NP, Fischer, J, Vreeken, J, <strong><em>Finding Interpretable Class-Specific Patterns through Efficient Neural Search</em></strong> accepted at AAAI Conference on Artificial Intelligence (AAAI), 2024. (23.8% acceptance rate, Core A*) [<a href="https://arxiv.org/abs/2312.04311">preprint</a>]</p>

<p>Hossain, I‡, Fischer, J‡, Burkholz, R*, Quackenbush, J*, <strong><em>Not all tickets are equal and we know it: Guiding pruning with domain-specific knowledge</em></strong> preprint: arXiv:2403.04805, 2024 [<a href="https://arxiv.org/abs/2403.04805">preprint</a>]<br>
‡*equal contribution</p>

<p>Saha, E‡, Fanfani, V‡, Mandros, P, Guebila, MB, Fischer, J, Shutta, KH, Glass, K, DeMeo, DL, Lopes-Ramos, CM, Quackenbush, J, <strong><em>Bayesian Optimized sample-specific Networks Obtained By Omics data (BONOBO)</em></strong> accepted at conference for Research in Computational Molecular Biology (RECOMB), 2024. (16.5% acceptance rate) [<a href="https://www.biorxiv.org/content/10.1101/2023.11.16.567119v1">preprint</a>]<br>
‡equal contribution</p>

<p>Hossain, I, Fanfani, V, Fischer, J, Quackenbush, J, Burkholz, J, <strong><em>Biologically informed NeuralODEs for genome-wide regulatory dynamics</em></strong> to appear in Genome Biology, BMC, 2024. (IF: 17.4, 2022) [<a href="https://www.biorxiv.org/content/10.1101/2023.02.24.529835v2">preprint</a>]</p>

<h3 id="2023">2023</h3>

<p>Hedderich, M‡, Fischer, J‡, Klakow, D, Vreeken, J, <strong><em>Understanding and Mitigating Classification Errors Through Interpretable Token Patterns</em></strong> Empirical Methods in Natural Language Processing (EMNLP) BlackboxNLP workshop, 2023. [<a href="https://arxiv.org/abs/2311.10920">preprint</a>]<br>
‡equal contribution</p>

<p>Saha, E, Guebila, MB, Fanfani, V, Fischer, J, Shutta, KH, Mandros, P, DeMeo, DL, Quackenbush, J, Lopes-Ramos, CM, <strong><em>Gene regulatory Networks Reveal Sex Difference in Lung Adenocarcinoma</em></strong> preprint: bioRxiv:10.1101/2023.09.22.559001v1, 2023. [<a href="https://www.biorxiv.org/content/10.1101/2023.09.22.559001v1">preprint</a>]</p>

<p>Kamp, M, Fischer, J, Vreeken, J, <strong><em>Federated Learning from Small Datasets</em></strong>. International Conference on Learning Representations (ICLR), OpenReview, 2023. (31.8% acceptance rate, Core A*) [<a href="https://openreview.net/forum?id=hDDV1lsRV8">PDF</a>]</p>

<p>Fischer, J, Burkholz, R, Vreeken, J, <strong><em>Preserving local densities in low-dimensional embeddings</em></strong>. preprint: arXiv:2301.13732, 2023.  [<a href="https://arxiv.org/abs/2301.13732">preprint</a>]</p>

<p>Fischer, J, Schulz, MH, <strong><em>Efficiently Quantifying DNA Methylation for Bulk- and Single-cell Bisulfite Data</em></strong>. Bioinformatics 39(6), Oxford University Press, 2023. (IF: 5.8, 2023) [<a href="https://academic.oup.com/bioinformatics/article/39/6/btad386/7199582">Article</a>]</p>

<h3 id="2022">2022</h3>

<p>Hedderich, M‡, Fischer, J‡, Klakow, D, Vreeken, J, <strong><em>Label-Descriptive Patterns and their Application to Characterizing Classification Errors</em></strong>. In: Proceedings of the International Conference on Machine Learning (ICML), PMLR, 2022. (21.9% acceptance rate, Core A*)  [<a href="https://proceedings.mlr.press/v162/hedderich22a/hedderich22a.pdf">PDF</a>]<br>
‡equal contribution</p>

<p>Fischer, J, Burkholz, R, <strong><em>Plant ‘n’ Seek: Can You Find the Winning Ticket?</em></strong>
International Conference on Learning Representations (ICLR), OpenReview, 2022. (32.9% acceptance rate, Core A*)  [<a href="https://openreview.net/pdf?id=9n9c8sf0xm">PDF</a>]</p>

<p>Marx, A, Fischer, J, <strong><em>Estimating Mutual Information via Geodesic kNN.</em></strong>
SIAM Conference on Data Mining (SDM), SIAM, 2022. (27.9% acceptance rate, Core A)  [<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977172.47">Article</a>]</p>

<h3 id="2021">2021</h3>

<p>Fischer, J, Vreeken, J, <strong><em>Differentiable Pattern Set Mining</em></strong>. In: Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), ACM, 2021. (15.4% acceptance rate, Core A*)  [<a href="https://dl.acm.org/doi/10.1145/3447548.3467348">Article</a>]</p>

<p>Fischer, J, Oláh, A, Vreeken, J, <strong><em>What’s in the Box? Explaining Neural Networks with Robust Rules</em></strong>. In: Proceedings of the International Conference on Machine Learning (ICML), PMLR, 2021. (21.4% acceptance rate, Core A*)  [<a href="https://proceedings.mlr.press/v139/fischer21b/fischer21b.pdf">PDF</a>]</p>

<p>Fischer, J, Ardakani, FB, Kattler, K, Walter, J, Schulz, MH, <strong><em>CpG content-dependent associations between transcription factors and histone modifications</em></strong>. Plos ONE 16(4): e0249985, 2021. (IF: 3.7, 2023)  [<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0249985">Article</a>]</p>

<p>Fischer, J‡, Gadhikar‡, A, Burkholz, R, <strong><em>Lottery Tickets with Nonzero Biases</em></strong>. preprint: arXiv:2110.11150, 2021.  [<a href="https://arxiv.org/abs/2110.11150">preprint</a>]<br>
‡equal contribution</p>

<p>Heiter, E, Fischer, J, Vreeken, J, <strong><em>Factoring out prior knowledge from low-dimensional embeddings</em></strong>. preprint: arXiv:2103.01828, 2021.  [<a href="https://arxiv.org/abs/2103.01828">preprint</a>]</p>

<h3 id="2020">2020</h3>

<p>Fischer, J, Vreeken, J, <strong><em>Discovering Succinct Pattern Sets Expressing Co-Occurrence and Mutual Exclusivity</em></strong>. In: Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), ACM, 2020. (16.8% acceptance rate, Core A*)  [<a href="https://dl.acm.org/doi/10.1145/3394486.3403124">Article</a>]</p>

<h3 id="2019">2019</h3>

<p>Fischer, J, Vreeken, J, <strong><em>Sets of Robust Rules, and How to Find Them</em></strong> In: Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Data (ECMLPKDD), Springer, 2019. (17.7% acceptance rate, Core A, ==selected plenary talk==, &lt;5% of accepted papers)  [<a href="https://link.springer.com/chapter/10.1007/978-3-030-46150-8_3">Article</a>]</p>

<p>Fischer, J, Schulz, MH, <strong><em>Fast and accurate bisulfite alignment and methylation calling for mammalian genomes</em></strong>. Talk at ISMB/ECCB, Basel, Switzerland, 2019.</p>

<h3 id="2018">2018</h3>

<p>Ardakani, FB Kattler, K, Nordström, KJ, Gasparoni, N, Gasparoni, G, Fuchs, S, Sinha, A, Barann, M, Ebert, P, Fischer, J, Hutter, B, Zipprich, G, Imbusch, CD, Felder, B, Eils, J, Brors, B, Lengauer, T, Manke, T, Rosenstiel, P, Walter, J, Schulz, MH, <strong><em>Integrative analysis of single-cell expression data reveals distinct regulatory states in bidirectional promoters</em></strong>. Epigenetics &amp; Chromatin 11(1): 66, 2018. (IF: 5.5, 2023)  [<a href="https://epigeneticsandchromatin.biomedcentral.com/articles/10.1186/s13072-018-0236-7">Article</a>]</p>

<p>Fischer, J, Schulz, MH, <strong><em>Fast and accurate bisulfite alignment and methylation calling for mammalian genomes</em></strong>. Short talk/poster at RECOMB-seq/RECOMB, Paris, France, 2018.</p>

<h3 id="theses">Theses</h3>

<p>Fischer, J, More than the sum of its parts – pattern mining, neural networks, and how they complement each other. Doctoral Dissertation, 2022.  [<a href="https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/33893?locale=en">PDF</a>]</p>
  </section>


    </main>
    


<footer class="background" style="--image: url('/group_website/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://scholar.google.com/citations?user=Gfc2NA4AAAAJ" data-tooltip="Google Scholar" data-style="bare" aria-label="Google Scholar">
      <i class="icon fa-brands fa-google"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://github.com/ExplainableMachines" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://twitter.com/JonasFischerML" data-tooltip="Twitter" data-style="bare" aria-label="Twitter">
      <i class="icon fa-brands fa-twitter"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © 2024
    Explainable Machine Learning Group
      |   Built with
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
